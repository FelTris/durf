{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac01fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow.compat.v1 as tf\n",
    "import math\n",
    "import numpy as np\n",
    "import itertools\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "\n",
    "tf.enable_eager_execution()\n",
    "\n",
    "from waymo_open_dataset.utils import range_image_utils\n",
    "from waymo_open_dataset.utils import transform_utils\n",
    "from waymo_open_dataset.utils import  frame_utils\n",
    "from waymo_open_dataset import dataset_pb2 as open_dataset\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import open3d as o3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e83de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILENAME = '/home/tristram/data/waymo/training-segment-10876852935525353526_1640_000_1660_000_with_camera_labels.tfrecord'\n",
    "dataset = tf.data.TFRecordDataset(FILENAME, compression_type='')\n",
    "frames = []\n",
    "for data in dataset:\n",
    "    frame = open_dataset.Frame()\n",
    "    frame.ParseFromString(bytearray(data.numpy()))\n",
    "    frames.append(frame)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b683452",
   "metadata": {},
   "source": [
    "## Poses for images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b215f253",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img_dir = '/home/tristram/data/waymo/seg3_5/images/'\n",
    "for i, elem in enumerate(frames):\n",
    "    if i < 5:\n",
    "        for j, img in enumerate(elem.images):\n",
    "            print(img.name)\n",
    "            if img.name == 4:\n",
    "                name = img.name - 1\n",
    "            elif img.name == 3:\n",
    "                name = img.name + 1\n",
    "            else:\n",
    "                name = img.name\n",
    "            print(str(i)+'_'+str(name)+'.jpg')\n",
    "            image = np.array(tf.image.decode_jpeg(img.image))\n",
    "            plt.imshow(image)\n",
    "            plt.axis('off')\n",
    "            plt.show()\n",
    "            sdir = img_dir+str(i)+'_'+str(name)+'.jpg'\n",
    "            print(sdir)\n",
    "            #plt.imsave(sdir, image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b23012",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_dir = '/home/tristram/data/waymo/seg2_5/'\n",
    "near = 3.0\n",
    "far = 200.0\n",
    "\n",
    "opengl2waymo = np.array([[0, 0, -1, 0],\n",
    "                        [-1, 0, 0, 0],\n",
    "                        [0, 1, 0, 0],\n",
    "                        [0, 0, 0, 1]])\n",
    "\n",
    "trafo2 = np.array([[-1, 0, 0, 0],\n",
    "                        [0, 0, 1, 0],\n",
    "                        [0, 1, 0, 0],\n",
    "                        [0, 0, 0, 1]])\n",
    "\n",
    "poses_3x5 = []\n",
    "cx = []\n",
    "cy = []\n",
    "for i, elem in enumerate(frames):\n",
    "    if i < 5:\n",
    "        for j, img in enumerate(elem.images):\n",
    "            if j >= 0:\n",
    "                #image = tf.image.decode_jpeg(img.image).numpy()\n",
    "                w = elem.context.camera_calibrations[img.name-1].width\n",
    "                h = elem.context.camera_calibrations[img.name-1].height\n",
    "                focal = elem.context.camera_calibrations[img.name-1].intrinsic[0]\n",
    "                cx.append(elem.context.camera_calibrations[img.name-1].intrinsic[2])\n",
    "                cy.append(elem.context.camera_calibrations[img.name-1].intrinsic[3])\n",
    "                hwf = np.array([h, w, focal]).reshape(3,1)\n",
    "                v2w = np.asarray(elem.pose.transform).reshape(4,4)\n",
    "                #print(elem.context.camera_calibrations)\n",
    "                c2v = np.asarray(elem.context.camera_calibrations[img.name-1].extrinsic.transform).reshape(4,4)\n",
    "                #print(c2v)\n",
    "                i2w = np.array(img.pose.transform).reshape(4, 4)\n",
    "                img_pose = np.matmul(i2w, c2v)\n",
    "                img_rot = R.from_matrix(img_pose[:3, :3])\n",
    "                img_aa = img_rot.as_rotvec()\n",
    "                \n",
    "                #print(focal)\n",
    "                pose = np.matmul(v2w, c2v)\n",
    "                pose_aa = R.from_matrix(pose[:3, :3])\n",
    "                pose_aa = pose_aa.as_rotvec()\n",
    "                #print((np.abs(img_aa) - np.abs(pose_aa)) * (180/np.pi))\n",
    "                #print(np.abs(img_pose[:3, 3]) - np.abs(pose[:3, 3]))\n",
    "                #print(pose)\n",
    "                pose = np.matmul(pose, opengl2waymo)\n",
    "                #x = pose[0,3].copy()\n",
    "                #y = pose[1,3].copy()\n",
    "                #z = pose[2,3].copy()\n",
    "                #pose[2,3] = y\n",
    "                #pose[1,3] = z\n",
    "                #pose[0,3] = -x\n",
    "                pose = np.matmul(trafo2, pose)\n",
    "\n",
    "\n",
    "                #pose = np.linalg.inv(pose)\n",
    "\n",
    "                poses_3x5.append(np.hstack((pose[:3,:4], hwf)))\n",
    "                #print(path+str(i)+'_'+str(j)+'.jpg')\n",
    "                #plt.imsave(path+str(i)+'_'+str(j)+'.jpg', image)\n",
    "        \n",
    "poses_flat = np.array(poses_3x5).reshape(-1, 15)\n",
    "poses_final = []\n",
    "for elem in poses_flat:\n",
    "    poses_final.append(np.concatenate((elem, [near, far])))\n",
    "poses_final = np.array(poses_final)\n",
    "pp = np.array([cx, cy]).transpose([1, 0])\n",
    "poses_final = np.concatenate([poses_final, pp], axis=-1)\n",
    "print(poses_final.shape)\n",
    "np.save(data_dir+'poses_bounds.npy', poses_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41032461",
   "metadata": {},
   "source": [
    "## Depth Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8fd358",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_dir = '/home/tristram/data/waymo/seg2_5/'\n",
    "scale = 4.0\n",
    "\n",
    "all_depth = []\n",
    "for i, elem in enumerate(frames):\n",
    "    if i < 5:\n",
    "        for j, img in enumerate(elem.images):\n",
    "            if j >= 0:\n",
    "                #image = tf.image.decode_jpeg(img.image).numpy()\n",
    "\n",
    "                (range_images,\\\n",
    "                 camera_projections,\\\n",
    "                 range_image_top_pose) = frame_utils.parse_range_image_and_camera_projection(elem)\n",
    "\n",
    "                points, cp_points = frame_utils.convert_range_image_to_point_cloud(elem,\n",
    "                                                                                   range_images,\n",
    "                                                                                   camera_projections,\n",
    "                                                                                   range_image_top_pose)\n",
    "\n",
    "                # 3d points in VEHICLE frame.\n",
    "                points_all = np.concatenate(points, axis=0)\n",
    "                # camera projection corresponding to each point.\n",
    "                cp_points_all = np.concatenate(cp_points, axis=0)\n",
    "                cp_points_all[:,1] = cp_points_all[:,1] / scale\n",
    "                cp_points_all[:,2] = cp_points_all[:,2] / scale\n",
    "                cp_points_all[:,4] = cp_points_all[:,4] / scale\n",
    "                cp_points_all[:,5] = cp_points_all[:,5] / scale\n",
    "\n",
    "                cp_points_all_concat = np.concatenate([cp_points_all, points_all], axis=-1)\n",
    "                cp_points_all_concat_tensor = tf.constant(cp_points_all_concat)\n",
    "\n",
    "                # The distance between lidar points and vehicle frame origin.\n",
    "                points_all_tensor = tf.norm(points_all, axis=-1, keepdims=True)\n",
    "                cp_points_all_tensor = tf.constant(cp_points_all, dtype=tf.int32)\n",
    "                                \n",
    "                mask = tf.equal(cp_points_all_tensor[..., 0], img.name)\n",
    "                overlap = tf.equal(cp_points_all_tensor[..., 3], img.name)\n",
    "\n",
    "                cp_points_all_tensor_mask = tf.cast(tf.gather_nd(cp_points_all_tensor,\n",
    "                                                            tf.where(mask)), dtype=tf.float32)\n",
    "                cp_points_all_tensor_overlap = tf.cast(tf.gather_nd(cp_points_all_tensor,\n",
    "                                                            tf.where(overlap)), dtype=tf.float32)\n",
    "                \n",
    "                points_all_tensor_mask = tf.gather_nd(points_all_tensor, tf.where(mask))\n",
    "                points_all_tensor_overlap = tf.gather_nd(points_all_tensor, tf.where(overlap))\n",
    "\n",
    "                projected_points_all_from_raw_data = tf.concat([cp_points_all_tensor_mask[..., 1:3],\n",
    "                                                                points_all_tensor_mask], axis=-1).numpy()\n",
    "                projected_point_overlap = tf.concat([cp_points_all_tensor_overlap[..., 4:6],\n",
    "                                                                points_all_tensor_overlap], axis=-1).numpy()\n",
    "\n",
    "                if projected_point_overlap.shape[0] != 0:\n",
    "                    projected_points_all_from_raw_data = np.concatenate([projected_points_all_from_raw_data,\n",
    "                                                                       projected_point_overlap])\n",
    "\n",
    "                w = int(elem.context.camera_calibrations[img.name-1].width / scale)\n",
    "                h = int(elem.context.camera_calibrations[img.name-1].height / scale)\n",
    "                resolution = (h, w)\n",
    "\n",
    "                depth = np.zeros(resolution)\n",
    "                for pts in projected_points_all_from_raw_data:\n",
    "                    if pts[0] < resolution[1] and  pts[1] < resolution[0]:\n",
    "                        if pts[2] < depth[int(pts[1]), int(pts[0])] or depth[int(pts[1]), int(pts[0])] == 0:\n",
    "                            depth[int(pts[1]), int(pts[0])] = pts[2]\n",
    "\n",
    "\n",
    "                \"\"\"img_d = visualize_depth(depth)\n",
    "\n",
    "                plt.figure(figsize=(50,50))\n",
    "                plt.imshow(img_d)\n",
    "                plt.show()\"\"\"\n",
    "\n",
    "                all_depth.append(depth)\n",
    "\n",
    "        \n",
    "all_depth = np.array(all_depth)\n",
    "\n",
    "print(len(all_depth))\n",
    "np.savez(data_dir+\"depth_images.npz\", all_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81c284c",
   "metadata": {},
   "outputs": [],
   "source": [
    "(range_images,\\\n",
    "camera_projections,\\\n",
    "range_image_top_pose) = frame_utils.parse_range_image_and_camera_projection(frames[1])\n",
    "\n",
    "points, cp_points = frame_utils.convert_range_image_to_point_cloud(frames[1],\n",
    "                                                                    range_images,\n",
    "                                                                    camera_projections,\n",
    "                                                                    range_image_top_pose)\n",
    "\n",
    "            # 3d points in VEHICLE frame.\n",
    "points_all = np.concatenate(points, axis=0)\n",
    "            # camera projection corresponding to each point.\n",
    "cp_points_all = np.concatenate(cp_points, axis=0)\n",
    "cp_points_all[:,1] = cp_points_all[:,1] / scale\n",
    "cp_points_all[:,2] = cp_points_all[:,2] / scale\n",
    "cp_points_all[:,4] = cp_points_all[:,4] / scale\n",
    "cp_points_all[:,5] = cp_points_all[:,5] / scale\n",
    "\n",
    "\n",
    "cp_points_all_concat = np.concatenate([cp_points_all, points_all], axis=-1)\n",
    "cp_points_all_concat_tensor = tf.constant(cp_points_all_concat)\n",
    "\n",
    "            # The distance between lidar points and vehicle frame origin.\n",
    "points_all_tensor = tf.norm(points_all, axis=-1, keepdims=True)\n",
    "cp_points_all_tensor = tf.constant(cp_points_all, dtype=tf.int32)\n",
    "\n",
    "mask = tf.equal(cp_points_all_tensor[..., 0], frames[1].images[2].name)\n",
    "\n",
    "cp_points_all_tensor = tf.cast(tf.gather_nd(cp_points_all_tensor,\n",
    "                                            tf.where(mask)), dtype=tf.float32)\n",
    "points_all_tensor = tf.gather_nd(points_all_tensor, tf.where(mask))\n",
    "\n",
    "projected_points_all_from_raw_data = tf.concat([cp_points_all_tensor[..., 1:3],\n",
    "                                                points_all_tensor], axis=-1).numpy()\n",
    "\n",
    "print(projected_points_all_from_raw_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c968229",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "depth = np.load('/home/tristram/data/waymo/seg1_2/'+'depth_images.npz', allow_pickle=True)['arr_0']\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "%matplotlib inline\n",
    "img = cv2.imread('/home/tristram/data/waymo/seg1_2/images_4/1_2.jpg')\n",
    "\n",
    "cmap = plt.cm.get_cmap(\"hsv\", 256)\n",
    "cmap = np.array([cmap(i) for i in range(256)])[:, :3] * 255\n",
    "\n",
    "for i in range(projected_points_all_from_raw_data.shape[0]):\n",
    "    depth = projected_points_all_from_raw_data[i, 2]\n",
    "    color = cmap[int(640.0 / depth), :]\n",
    "    cv2.circle(\n",
    "        img,\n",
    "        (int(np.rint(projected_points_all_from_raw_data[i, 0])), int(np.rint(projected_points_all_from_raw_data[i, 1]))),\n",
    "        0,\n",
    "        color=tuple(color),\n",
    "        thickness=-1,\n",
    "        )\n",
    "\n",
    "plt.figure(figsize=(50,50))\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4197cd81",
   "metadata": {},
   "outputs": [],
   "source": [
    "h = np.linspace(0, 320, num=320, dtype=np.int)\n",
    "w = np.linspace(0, 480, num=480, dtype=np.int)\n",
    "\n",
    "img = np.meshgrid(w, h)\n",
    "\n",
    "depth = np.load('/home/tristram/data/waymo/seg1_5/'+'depth_images.npz', allow_pickle=True)['arr_0']\n",
    "\n",
    "pts = np.zeros((320, 480, 3))\n",
    "pts[:,:,0] = img[0]\n",
    "pts[:,:,1] = img[1]\n",
    "pts[:,:,2] = depth[1]\n",
    "\n",
    "pts = pts.reshape(-1,3)\n",
    "pts[pts==0.0] = -1000.0\n",
    "\n",
    "test = o3d.geometry.PointCloud(o3d.utility.Vector3dVector(pts))\n",
    "o3d.io.write_point_cloud('/home/tristram/nerf_results/WAYMO1_5_ds_3_200_log_4x128/' + \"test0.ply\", test)\n",
    "\n",
    "#plt.imshow(depth[1])\n",
    "#plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9623ce54",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/home/tristram/data/waymo/seg1_5/'\n",
    "\n",
    "sky = np.load('/home/tristram/data/waymo/seg1_20/'+'sky_masks.npz', allow_pickle=True)['arr_0']\n",
    "save = []\n",
    "for i, elem in enumerate(sky):\n",
    "    if i < 25:\n",
    "        save.append(elem)\n",
    "\n",
    "save = np.array(save)\n",
    "print(save.shape)\n",
    "np.savez(data_dir+'sky_masks.npz', save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a16e9e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "load = np.load('/home/tristram/data/waymo/seg2_5/'+'depth_images.npz', allow_pickle=True)['arr_0']\n",
    "\n",
    "for l in load:\n",
    "    \n",
    "    img = visualize_depth(l)\n",
    "    print(l.shape)\n",
    "    plt.figure(figsize=(50,50))\n",
    "    plt.imshow(img)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd27fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "imgdir = data_dir + 'images_4/'\n",
    "if not utils.file_exists(imgdir):\n",
    "    raise ValueError('Image folder {} does not exist.'.format(imgdir))\n",
    "imgfiles = [\n",
    "    path.join(imgdir, f) for f in natsorted(utils.listdir(imgdir))\n",
    "    if f.endswith('JPG') or f.endswith('jpg') or f.endswith('png')\n",
    "        ]\n",
    "\n",
    "images = []\n",
    "for imgfile in imgfiles:\n",
    "    with utils.open_file(imgfile, 'rb') as imgin:\n",
    "        image = np.array(Image.open(imgin), dtype=np.float32) / 255.\n",
    "        images.append(image)\n",
    "images = np.array(images, dtype=object)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(images[4])\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(images[9])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f1d17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "veh = np.load(data_dir + 'poses_bounds.npy')\n",
    "cams = veh[:, :15].reshape(-1,3,5).copy()\n",
    "cc = cams[:,:3,:4].copy()\n",
    "cams_centered, _ = center_poses(cc)\n",
    "cams[:,:3,:4] = cams_centered\n",
    "cams = cams.reshape(-1,15)\n",
    "veh[:,:15] = cams\n",
    "\n",
    "print(cams_centered[0])\n",
    "print(poses1[0])\n",
    "print(poses2[0, :3, :4])\n",
    "\n",
    "#np.save(data_dir+'test_poses.npy', veh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4491672",
   "metadata": {},
   "outputs": [],
   "source": [
    "depth = np.load('/home/tristram/data/waymo/seg1_10_0/'+'depth_images.npy')\n",
    "print(len(depth))\n",
    "print(depth.shape)\n",
    "print(depth[0])\n",
    "img_d = visualize_depth(depth[0])\n",
    "plt.figure(figsize=(50,50))\n",
    "plt.imshow(img_d)\n",
    "plt.show()\n",
    "\n",
    "img_d = visualize_depth(depth[1])\n",
    "plt.figure(figsize=(50,50))\n",
    "plt.imshow(img_d)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be4a172",
   "metadata": {},
   "source": [
    "## Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077a1ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECK IF SHAPES MATCH\n",
    "\n",
    "from PIL import Image\n",
    "from natsort import natsorted\n",
    "path = '/home/tristram/data/waymo/seg1_20/images_4/'\n",
    "\n",
    "imgs = natsorted(os.listdir(path))\n",
    "poses = np.load('/home/tristram/data/waymo/seg1_20/poses_bounds.npy')[:,:15]\n",
    "poses = poses.reshape(-1, 3, 5)\n",
    "depth = np.load('/home/tristram/data/waymo/seg1_20/depth_images.npz', allow_pickle=True)['arr_0']\n",
    "sky = np.load('/home/tristram/data/waymo/seg1_20/sky_masks.npz', allow_pickle=True)['arr_0']\n",
    "\n",
    "for i, name in enumerate(imgs):\n",
    "    img = np.array(Image.open(path+name))\n",
    "    if img.shape[0] != int(poses[i, 0, -1] / 4):\n",
    "        print(name)\n",
    "    if img.shape[1] != int(poses[i, 1, -1] / 4):\n",
    "        print(name)\n",
    "    if img.shape[:2] != depth[i].shape:\n",
    "        print(name)\n",
    "    if img.shape[:2] != sky[i].shape:\n",
    "        print(name)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdda40b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "def visualize_depth(depth, cmap=cv2.COLORMAP_TWILIGHT_SHIFTED):\n",
    "    \"\"\"\n",
    "    depth: (H, W)\n",
    "    \"\"\"\n",
    "    x = depth\n",
    "    \n",
    "    x = np.nan_to_num(x) # change nan to 0\n",
    "    mi = np.min(x) # get minimum depth\n",
    "    ma = np.max(x)\n",
    "    x = (x-mi)/(ma-mi+1e-8) # normalize to 0~1\n",
    "    x = (255*x).astype(np.uint8)\n",
    "    x_ = Image.fromarray(cv2.applyColorMap(x, cmap))\n",
    "    return x_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c140812",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "from natsort import natsorted\n",
    "\n",
    "old = '/home/tristram/data/waymo/segment1/images_4/'\n",
    "names = natsorted(os.listdir('/home/tristram/data/waymo/segment1/images/'))\n",
    "new = '/home/tristram/data/waymo/seg1_5/images_4/'\n",
    "\n",
    "for i, elem in enumerate(names):\n",
    "    if i < 5 * 5:\n",
    "        shutil.copy(old+elem, new+elem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d46cb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d as o3d\n",
    "\n",
    "(range_images,\\\n",
    "camera_projections,\\\n",
    "range_image_top_pose) = frame_utils.parse_range_image_and_camera_projection(frames[0])\n",
    "\n",
    "\n",
    "\n",
    "# points are given in vehicle coordinates\n",
    "points, cp_points = frame_utils.convert_range_image_to_point_cloud(\n",
    "    frames[0],\n",
    "    range_images,\n",
    "    camera_projections,\n",
    "    range_image_top_pose)\n",
    "points_all = np.concatenate(points, axis=0)\n",
    "points_hom = np.ones((points_all.shape[0], 4))\n",
    "points_hom[:,:3] = points_all\n",
    "\n",
    "# this transforms from vehicle to world coordinates\n",
    "v2w = np.asarray(frames[0].pose.transform).reshape(4,4)\n",
    "\n",
    "opengl2waymo = np.array([[0, 0, -1, 0],\n",
    "                        [-1, 0, 0, 0],\n",
    "                        [0, 1, 0, 0],\n",
    "                        [0, 0, 0, 1]])\n",
    "\n",
    "# transform points to world coordinates\n",
    "points_w = np.matmul(points_hom, v2w.T)\n",
    "points_wgl = np.matmul(points_w, opengl2waymo)\n",
    "\n",
    "data_dir = '/home/tristram/data/waymo/segment1/'\n",
    "\n",
    "test = o3d.geometry.PointCloud(o3d.utility.Vector3dVector(points_wgl[:,:3]))\n",
    "o3d.io.write_point_cloud(data_dir + \"test0.ply\", test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d37b1bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
