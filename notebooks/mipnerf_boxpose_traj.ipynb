{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f2fe56",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "# needed for notebook to find other directories\n",
    "module_path = os.path.abspath(os.path.join('../mipnerf'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "# needed for notebook to find other directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5930d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "import flax\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import random\n",
    "import gin\n",
    "from absl import flags\n",
    "import functools\n",
    "from flax.training import checkpoints\n",
    "from mipnerf.internal import utils\n",
    "from mipnerf.internal import datasets\n",
    "from mipnerf.internal import c2f_obb_dataset\n",
    "from mipnerf.internal import obbpose_dataset\n",
    "from mipnerf.internal import models\n",
    "from mipnerf.internal import obbpose_model\n",
    "from mipnerf.internal import d_models\n",
    "from mipnerf.internal import d_models360\n",
    "\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.transform import Rotation as R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29901686",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Config:\n",
    "  \"\"\"Configuration flags for everything.\"\"\"\n",
    "  dataset_loader: str = 'waymo'  # The type of dataset loader to use.\n",
    "  batching: str = 'timestep'  # Batch composition, [single_image, all_images].\n",
    "  batch_size: int = 512  # The number of rays/pixels in each batch.\n",
    "  factor: int = 4  # The downsample factor of images, 0 for no downsampling.\n",
    "  spherify: bool = True  # Set to True for spherical 360 scenes.\n",
    "  centering: bool = True  # this determines if poses are centered around zero or not\n",
    "  render_path: bool = False  # If True, render a path. Used only by LLFF.\n",
    "  llffhold: int = 11  # Use every Nth image for the test set. Used only by LLFF.\n",
    "  timesteps: int = 5  # How many timesteps the current scene has (a bit of a crutch right now, integrate to dataset?)\n",
    "  lr_init: float = 5e-4  # The initial learning rate.\n",
    "  lr_final: float = 5e-6  # The final learning rate.\n",
    "  lr_delay_steps: int = 2500  # The number of \"warmup\" learning steps.\n",
    "  eps_delay_steps: int = 0  # The number of \"warmup\" learning steps.\n",
    "  eps_init: int = 3  # Initial interval for near loss\n",
    "  eps_final: int = 0.2  # Final interval for near loss\n",
    "  l2_init: int = 1  # Initial value for l2reg for deformation model\n",
    "  l2_final: int = 0  # Final value for l2reg for deformation model\n",
    "  l2_delay_steps: int = 5000  # reduce l2reg after this many steps\n",
    "  psreg_init: float = 10e5  # start value for pose regularization\n",
    "  psreg_final: float = 10e-1  # end value for pose regularization\n",
    "  psreg_delay_steps: int = 5000  # after this many steps, start decreasing psreg\n",
    "  psreg_delay_mult: float = 1.0\n",
    "  random_box: bool = False\n",
    "  random_yaw: bool = False\n",
    "  box_noise: float = 0.5\n",
    "  yaw_noise: float = 5.  # rotational noise in degrees added to box yaw / heading angle\n",
    "  c2f_steps: list = (5000, 10000, 15000)  # The number of steps after which rays of higher resolutions should be loaded\n",
    "  lr_delay_mult: float = 0.01  # How much sever the \"warmup\" should be.\n",
    "  grad_max_norm: float = 0.  # Gradient clipping magnitude, disabled if == 0.\n",
    "  grad_max_val: float = 0.  # Gradient clipping value, disabled if == 0.\n",
    "  max_steps: int = 200000  # The number of optimization steps.\n",
    "  save_every: int = 50000  # The number of steps to save a checkpoint.\n",
    "  print_every: int = 100  # The number of steps between reports to tensorboard.\n",
    "  gc_every: int = 10000  # The number of steps between garbage collections.\n",
    "  test_render_interval: int = 1  # The interval between images saved to disk.\n",
    "  disable_multiscale_loss: bool = False  # If True, disable multiscale loss.\n",
    "  randomized: bool = True  # Use randomized stratified sampling.\n",
    "  near: float = 0.0  # Near plane distance.\n",
    "  far: float = 40.  # Far plane distance.\n",
    "  coarse_loss_mult: float = 0.1  # How much to downweight the coarse loss(es).\n",
    "  weight_decay_mult: float = 0.  # The multiplier on weight decay.\n",
    "  white_bkgd: bool = False  # If True, use white as the background (black o.w.).\n",
    "  rand_bkgd: bool = False  # If True, use random color as background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab9c244",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "def visualize_depth(depth, cmap=cv2.COLORMAP_TWILIGHT_SHIFTED):\n",
    "    \"\"\"\n",
    "    depth: (H, W)\n",
    "    \"\"\"\n",
    "    x = depth\n",
    "    x = np.nan_to_num(x) # change nan to 0\n",
    "    mi = np.min(x) # get minimum depth\n",
    "    ma = np.max(x)\n",
    "    x = (x-mi)/(ma-mi+1e-8) # normalize to 0~1\n",
    "    x = (255*x).astype(np.uint8)\n",
    "    x_ = Image.fromarray(cv2.applyColorMap(x, cmap))\n",
    "    return x_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad8064d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def generate_rays_original(camtoworlds, dataset, img):\n",
    "    \"\"\"Generating rays for all images.\"\"\"\n",
    "    x, y = np.meshgrid(  # pylint: disable=unbalanced-tuple-unpacking\n",
    "        np.arange(dataset.w[img], dtype=np.float32),  # X-Axis (columns)\n",
    "        np.arange(dataset.h[img], dtype=np.float32),  # Y-Axis (rows)\n",
    "        indexing='xy')\n",
    "    camera_dirs = np.stack(\n",
    "        [(x - dataset.w[img] * 0.5) / dataset.focal[img],\n",
    "         -(y - dataset.h[img] * 0.5) / dataset.focal[img], -np.ones_like(x)],axis=-1)\n",
    "    directions = ((camera_dirs[None, ..., None, :] *\n",
    "                   camtoworlds[:3, :3]).sum(axis=-1))\n",
    "    origins = np.broadcast_to(camtoworlds[:3, -1],directions.shape)\n",
    "    viewdirs = directions / np.linalg.norm(directions, axis=-1, keepdims=True)\n",
    "\n",
    "    # Distance from each unit-norm direction vector to its x-axis neighbor.\n",
    "    dx = np.sqrt(np.sum((directions[:, :-1, :, :] - directions[:, 1:, :, :]) ** 2, -1))\n",
    "    dx = np.concatenate([dx, dx[:, -2:-1, :]], 1)\n",
    "    # Cut the distance in half, and then round it out so that it's\n",
    "    # halfway between inscribed by / circumscribed about the pixel.\n",
    "\n",
    "    radii = dx[..., None] * 2 / np.sqrt(12)\n",
    "\n",
    "    ones = np.ones_like(origins[..., :1]).squeeze()\n",
    "    rays = BoxRays(\n",
    "            origins=origins.squeeze(),\n",
    "            directions=directions.squeeze(),\n",
    "            viewdirs=viewdirs.squeeze(),\n",
    "            radii=radii.squeeze(),\n",
    "            lossmult=ones.squeeze(),\n",
    "            near=ones * dataset.near,\n",
    "            far=ones * dataset.far,)\n",
    "    return rays\n",
    "\n",
    "def generate_rays_waymo(camtoworlds, dataset, img, pp=0):\n",
    "    \"\"\"Generating rays for all images.\"\"\"\n",
    "    x, y = np.meshgrid(  # pylint: disable=unbalanced-tuple-unpacking\n",
    "        np.arange(dataset.w[img], dtype=np.float32),  # X-Axis (columns)\n",
    "        np.arange(dataset.h[img], dtype=np.float32),  # Y-Axis (rows)\n",
    "        indexing='xy')\n",
    "\n",
    "    pp_scale = pp / 4\n",
    "\n",
    "    camera_dirs = np.stack(\n",
    "        [(x - pp_scale[0] + 0.5) / dataset.focal[img],\n",
    "         -(y - pp_scale[1] + 0.5) / dataset.focal[img], -np.ones_like(x)],axis=-1)\n",
    "\n",
    "    directions = ((camera_dirs[None, ..., None, :] *\n",
    "                   camtoworlds[:3, :3]).sum(axis=-1))\n",
    "    origins = np.broadcast_to(camtoworlds[:3, -1],directions.shape)\n",
    "    viewdirs = directions / np.linalg.norm(directions, axis=-1, keepdims=True)\n",
    "\n",
    "    # Distance from each unit-norm direction vector to its x-axis neighbor.\n",
    "    dx = np.sqrt(np.sum((directions[:, :-1, :, :] - directions[:, 1:, :, :]) ** 2, -1))\n",
    "    dx = np.concatenate([dx, dx[:, -2:-1, :]], 1)\n",
    "    # Cut the distance in half, and then round it out so that it's\n",
    "    # halfway between inscribed by / circumscribed about the pixel.\n",
    "\n",
    "    radii = dx[..., None] * 2 / np.sqrt(12)\n",
    "\n",
    "    ones = np.ones_like(origins[..., :1]).squeeze()\n",
    "    rays = BoxRays(\n",
    "            origins=origins.squeeze(),\n",
    "            directions=directions.squeeze(),\n",
    "            viewdirs=viewdirs.squeeze(),\n",
    "            radii=radii.squeeze(),\n",
    "            lossmult=ones.squeeze(),\n",
    "            near=ones * dataset.near,\n",
    "            far=ones * dataset.far,)\n",
    "    return rays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ccf0701",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def convert_to_ndc(origins, directions, focal, w, h, near=1.):\n",
    "    \"\"\"Convert a set of rays to NDC coordinates.\"\"\"\n",
    "    # Shift ray origins to near plane\n",
    "    t = -(near + origins[..., 2]) / directions[..., 2]\n",
    "    origins = origins + t[..., None] * directions\n",
    "\n",
    "    dx, dy, dz = tuple(np.moveaxis(directions, -1, 0))\n",
    "    ox, oy, oz = tuple(np.moveaxis(origins, -1, 0))\n",
    "\n",
    "    # Projection\n",
    "    o0 = -((2 * focal) / w) * (ox / oz)\n",
    "    o1 = -((2 * focal) / h) * (oy / oz)\n",
    "    o2 = 1 + 2 * near / oz\n",
    "\n",
    "    d0 = -((2 * focal) / w) * (dx / dz - ox / oz)\n",
    "    d1 = -((2 * focal) / h) * (dy / dz - oy / oz)\n",
    "    d2 = -2 * near / oz\n",
    "\n",
    "    origins = np.stack([o0, o1, o2], -1)\n",
    "    directions = np.stack([d0, d1, d2], -1)\n",
    "    return origins, directions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7080a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def generate_ndc_rays(camtoworlds, dataset):\n",
    "    \"\"\"Generate normalized device coordinate rays for llff.\"\"\"\n",
    "    rays = generate_rays_original(camtoworlds, dataset)\n",
    "    ndc_origins, ndc_directions = convert_to_ndc(rays.origins,\n",
    "                                                 rays.directions,\n",
    "                                                 dataset.focal[5], dataset.w[5], dataset.h[5])\n",
    "\n",
    "    mat = ndc_origins\n",
    "    # Distance from each unit-norm direction vector to its x-axis neighbor.\n",
    "    dx = np.sqrt(np.sum((mat[:, :-1, :, :] - mat[:, 1:, :, :]) ** 2, -1))\n",
    "    dx = np.concatenate([dx, dx[:, -2:-1, :]], 1)\n",
    "\n",
    "    dy = np.sqrt(np.sum((mat[:, :, :-1, :] - mat[:, :, 1:, :]) ** 2, -1))\n",
    "    dy = np.concatenate([dy, dy[:, :, -2:-1]], 2)\n",
    "    # Cut the distance in half, and then round it out so that it's\n",
    "    # halfway between inscribed by / circumscribed about the pixel.\n",
    "    radii = (0.5 * (dx + dy))[..., None] * 2 / np.sqrt(12)\n",
    "    \n",
    "    ones = np.ones_like(ndc_origins[..., :1].squeeze())\n",
    "    ndcrays = Rays(\n",
    "                origins=ndc_origins.squeeze(),\n",
    "                directions=ndc_directions.squeeze(),\n",
    "                viewdirs=rays.directions.squeeze(),\n",
    "                radii=radii.squeeze(),\n",
    "                lossmult=ones,\n",
    "                near=ones * dataset.near,\n",
    "                far=ones * dataset.far)\n",
    "    \n",
    "    return ndcrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb28a1f4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def _recenter_poses(poses):\n",
    "    \"\"\"Recenter poses according to the original NeRF code.\"\"\"\n",
    "    poses_ = poses.copy()\n",
    "    bottom = np.reshape([0, 0, 0, 1.], [1, 4])\n",
    "    c2w = _poses_avg(poses)\n",
    "    c2w = np.concatenate([c2w[:3, :4], bottom], -2)\n",
    "    bottom = np.tile(np.reshape(bottom, [1, 1, 4]), [poses.shape[0], 1, 1])\n",
    "    poses = np.concatenate([poses[:, :3, :4], bottom], -2)\n",
    "    poses = np.linalg.inv(c2w) @ poses\n",
    "    poses_[:, :3, :4] = poses[:, :3, :4]\n",
    "    poses = poses_\n",
    "    return poses, c2w\n",
    "\n",
    "def _poses_avg(poses):\n",
    "    \"\"\"Average poses according to the original NeRF code.\"\"\"\n",
    "    hwf = poses[0, :3, -1:]\n",
    "    center = poses[:, :3, 3].mean(0)\n",
    "    vec2 = _normalize(poses[:, :3, 2].sum(0))\n",
    "    up = poses[:, :3, 1].sum(0)\n",
    "    c2w = np.concatenate([_viewmatrix(vec2, up, center), hwf], 1)\n",
    "    return c2w\n",
    "    \n",
    "def _normalize(x):\n",
    "    \"\"\"Normalization helper function.\"\"\"\n",
    "    return x / np.linalg.norm(x)\n",
    "    \n",
    "def _viewmatrix(z, up, pos):\n",
    "    \"\"\"Construct lookat view matrix.\"\"\"\n",
    "    vec2 = _normalize(z)\n",
    "    vec1_avg = up\n",
    "    vec0 = _normalize(np.cross(vec1_avg, vec2))\n",
    "    vec1 = _normalize(np.cross(vec2, vec0))\n",
    "    m = np.stack([vec0, vec1, vec2, pos], 1)\n",
    "    return m\n",
    "\n",
    "poses_arr = np.load('/home/tristram/data/waymo/seg1_5_center/poses_bounds.npy')\n",
    "#poses = poses_arr[:, :-2].reshape([-1, 3, 5]).transpose([1, 2, 0])\n",
    "#bds = poses_arr[:, -2:].transpose([1, 0])\n",
    "poses = poses_arr[:, :-4].reshape([-1, 3, 5]).transpose([1, 2, 0])\n",
    "bds = poses_arr[:, -4:-2].transpose([1, 0])\n",
    "princip_point = poses_arr[:, -2:]\n",
    "\n",
    "# Update poses according to downsampling.\n",
    "poses[:2, 4, :] = np.array([320,480]).reshape([2, 1])\n",
    "poses[2, 4, :] = poses[2, 4, :] * 1. / 4.0\n",
    "\n",
    "poses = np.moveaxis(poses, -1, 0).astype(np.float32)\n",
    "poses, c2w = _recenter_poses(poses)\n",
    "poses[:, :3, 3] /= 5.0\n",
    "\n",
    "\n",
    "box_dict = np.load('/home/tristram/data/waymo/seg1_5_center/3D_boxes.npy', allow_pickle=True).item()\n",
    "box_pose = []\n",
    "box_ext = []\n",
    "for key in box_dict:\n",
    "    if 'center' in key:\n",
    "        box_pose.append(box_dict[key])\n",
    "    elif 'ext' in key:\n",
    "        box_ext.append(box_dict[key])\n",
    "box_pose = np.array(box_pose)\n",
    "box_ext = np.array(box_ext)\n",
    "\n",
    "box_pose = np.linalg.inv(c2w) @ box_pose\n",
    "box_pose[:, :3, 3] /= 5.0 #* 2.0\n",
    "box_ext /= 5.0 * 2.0\n",
    "\n",
    "yaw = R.from_matrix(np.linalg.inv(box_pose[:, :3, :3]))  # take inverse of rotation matrix to go from world to object\n",
    "yaw = np.array(yaw.as_rotvec())   \n",
    "\n",
    "obbpose = np.concatenate([box_pose[:, :3, 3], yaw], axis=-1)\n",
    "rel_pose = {}\n",
    "cars = []\n",
    "bpose = [k for k in box_dict if 'center' in k]\n",
    "for i, key in enumerate(bpose):\n",
    "    if '1_' in key and 'center' in key:\n",
    "        can_pose = box_pose[i]\n",
    "        ts, car, _ = key.split('_')\n",
    "        cars.append(int(car))\n",
    "        rel_pose[ts + '_' + car + '_rel'] = np.eye(4)\n",
    "        box_dict[key] = obbpose[i]\n",
    "        box_dict[ts + '_' + car + '_ext'] = box_ext[i]\n",
    "    else:\n",
    "        ts, car, _ = key.split('_')\n",
    "        cars.append(int(car))\n",
    "        rel_pose[ts+'_'+car+'_rel'] = np.matmul(can_pose, np.linalg.inv(box_pose[i]))\n",
    "        box_dict[key] = obbpose[i]\n",
    "        box_dict[ts + '_' + car + '_ext'] = box_ext[i]\n",
    "        \n",
    "cars = np.unique(np.array(cars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660aa9f4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "BoxRays = collections.namedtuple(\n",
    "    'BoxRays',\n",
    "    ('origins', 'directions',\n",
    "     'viewdirs', 'radii', 'lossmult',\n",
    "     'near', 'far'))\n",
    "\n",
    "config = Config()\n",
    "\n",
    "dataset = obbpose_dataset.get_dataset('render', '/home/tristram/data/waymo/seg1_5_center', config)\n",
    "\n",
    "#example_batch = dataset.peek()\n",
    "#example_batch['box'] = example_batch['box'][None, ...]\n",
    "\n",
    "model, init_variables = obbpose_model.construct_mipnerf(\n",
    "      random.PRNGKey(20200823), dataset.peek())\n",
    "optimizer = flax.optim.Adam(config.lr_init).create(init_variables)\n",
    "state = utils.TrainState(optimizer=optimizer)\n",
    "del optimizer, init_variables\n",
    "\n",
    "# Because this is only used for test set rendering, we disable randomization.\n",
    "def render_eval_fn(variables, _, batch):\n",
    "    return jax.lax.all_gather(\n",
    "        model.apply(\n",
    "                variables,\n",
    "                random.PRNGKey(0),  # Unused.\n",
    "                batch['rays'],\n",
    "                batch['init'],\n",
    "                batch['ext'],\n",
    "                batch['ts'],\n",
    "                randomized=False,\n",
    "                white_bkgd=config.white_bkgd,\n",
    "                rand_bkgd=False,\n",
    "                alpha=batch['alpha']),\n",
    "            axis_name='batch')\n",
    "\n",
    "render_eval_pfn = jax.pmap(\n",
    "    render_eval_fn,\n",
    "    in_axes=(None, None, 0),  # Only distribute the data input.\n",
    "    donate_argnums=(2,),\n",
    "    axis_name='batch',\n",
    ")\n",
    "exp_name = 'Waymo_dend_cntr02_0_40_8_256_10fipe_noopt_noboxcntr'\n",
    "state = checkpoints.restore_checkpoint('/home/tristram/nerf_results/'+exp_name+'/seg1_5_center', \n",
    "                                      state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acab3913",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "    #bottom = np.reshape([0, 0, 0, 1.], [1, 4])\n",
    "    #pose = poses[5]\n",
    "    #pose = np.concatenate([pose[:3, :4], bottom], -2)\n",
    "    #c2w = render_poses[0]\n",
    "    traj = np.load('/home/tristram/exp_results/giftest/seg1_5_traj_opt.npz', allow_pickle=True)['arr_0']\n",
    "    save_dir = '/home/tristram/Pictures/giftemp4/'\n",
    "    \n",
    "    images = []\n",
    "    for i, elem in enumerate(traj):\n",
    "        if i <= len(traj):\n",
    "            c2w = elem[0]\n",
    "            ts = elem[1]\n",
    "            rays = generate_rays_waymo(c2w, dataset, img=2, pp=princip_point[2])\n",
    "            #rays = generate_rays_original(c2w, dataset, img=20)\n",
    "\n",
    "            init = []\n",
    "            for j in range(int(poses.shape[0]/5)):\n",
    "                init.append(np.array(\n",
    "                    [np.concatenate(box_dict[str(j + 1) + '_' + str(c) + '_center'][:, None], axis=0) for c in\n",
    "                    cars]).reshape(-1, 6))\n",
    "            init = np.array(init).reshape(int(poses.shape[0]/5), -1, 6)\n",
    "            box = np.array([np.concatenate(box_dict[str(1) + '_' + str(c) + '_center'][:, None], axis=0) for c in\n",
    "                     cars]).reshape(-1, 6)\n",
    "            ext = np.array([np.concatenate(box_dict[str(1) + '_' + str(c) + '_ext'][..., None], axis=0) for c in\n",
    "                     cars]).reshape(-1, 3)\n",
    "            rel = np.array([np.concatenate(rel_pose[str(1) + '_' + str(c) + '_rel'], axis=0) for c in\n",
    "                     cars]).reshape(-1, 4, 4)\n",
    "\n",
    "            pred_color, pred_distance, pred_acc = obbpose_model.render_image(\n",
    "                    functools.partial(render_eval_pfn, state.optimizer.target),\n",
    "                    rays,\n",
    "                    init,\n",
    "                    ext,\n",
    "                    ts,\n",
    "                    None,\n",
    "                    alpha=10,\n",
    "                    chunk=2048)\n",
    "            print(i+1, '/'+str(len(traj)))\n",
    "            \n",
    "            plt.figure(2, figsize=(20,6))\n",
    "            plt.imshow(pred_color)\n",
    "            plt.show()\n",
    "    \n",
    "            img_d = visualize_depth(pred_distance)\n",
    "            plt.figure(2, figsize=(20,6))\n",
    "            plt.imshow(img_d)\n",
    "            plt.show()\n",
    "    \n",
    "            imgsave = np.clip(pred_color, 0, 1)\n",
    "            plt.imsave(save_dir+exp_name+'_rgb_ts_'+str(i)+'.png', imgsave)\n",
    "            img_d.save(save_dir+exp_name+'_depth_ts_'+str(i)+'.png')\n",
    "            \n",
    "            images.append(pred_color)\n",
    "        \n",
    "        #plt.figure(2, figsize=(20,6))\n",
    "        #plt.imshow(pred_color)\n",
    "        #plt.show()\n",
    "\n",
    "        #img_d = visualize_depth(pred_distance)\n",
    "        #plt.figure(2, figsize=(20,6))\n",
    "        #plt.imshow(img_d)\n",
    "        #plt.show()\"\"\"\n",
    "    import imageio\n",
    "    imageio.mimsave('/home/tristram/exp_results/giftest/test_carla.gif', images, fps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cfa36b6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from ipywidgets import interactive, widgets\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "save_dir = '/home/tristram/Pictures/eval_traj/'\n",
    "\n",
    "traj = []\n",
    "def f(x, y, z, rx, ry, rz, ts):\n",
    "    \n",
    "    c2w = np.array([\n",
    "        [1,0,0,x],\n",
    "        [0,1,0,y],\n",
    "        [0,0,1,z],\n",
    "        [0,0,0,1]\n",
    "    ])\n",
    "    \n",
    "    R_X = np.array([\n",
    "      [ 1.0,  0.0, 0.0, 0.0],\n",
    "      [ 0.0,  np.cos(rx*3.1415/180), -np.sin(rx*3.1415/180), 0.0],\n",
    "      [ 0.0,  np.sin(rx*3.1415/180), np.cos(rx*3.1415/180), 0.0],\n",
    "      [ 0.0,  0.0, 0.0, 1.0]])\n",
    "    \n",
    "    R_Y = np.array([\n",
    "      [ np.cos(ry*3.1415/180),  0.0, np.sin(ry*3.1415/180), 0.0],\n",
    "      [ 0.0,  1.0, 0.0, 0.0],\n",
    "      [ -np.sin(ry*3.1415/180),  0.0, np.cos(ry*3.1415/180), 0.0],\n",
    "      [ 0.0,  0.0, 0.0, 1.0]])\n",
    "    \n",
    "    R_Z = np.array([\n",
    "      [ np.cos(rz*3.1415/180),  -np.sin(rz*3.1415/180), 0.0, 0.0],\n",
    "      [ np.sin(rz*3.1415/180),  np.cos(rz*3.1415/180), 0.0, 0.0],\n",
    "      [ 0.0,  0.0, 1.0, 0.0],\n",
    "      [ 0.0,  0.0, 0.0, 1.0]])\n",
    "    \"\"\"\n",
    "    ot = np.array([\n",
    "        [1,0,0,ox],\n",
    "        [0,1,0,oy],\n",
    "        [0,0,1,oz],\n",
    "        [0,0,0,1]\n",
    "    ])\n",
    "    \n",
    "    OR_X = np.array([\n",
    "      [ 1.0,  0.0, 0.0, 0.0],\n",
    "      [ 0.0,  np.cos(orx*3.1415/180), -np.sin(orx*3.1415/180), 0.0],\n",
    "      [ 0.0,  np.sin(orx*3.1415/180), np.cos(orx*3.1415/180), 0.0],\n",
    "      [ 0.0,  0.0, 0.0, 1.0]])\n",
    "    \n",
    "    OR_Y = np.array([\n",
    "      [ np.cos(ory*3.1415/180),  0.0, np.sin(ory*3.1415/180), 0.0],\n",
    "      [ 0.0,  1.0, 0.0, 0.0],\n",
    "      [ -np.sin(ory*3.1415/180),  0.0, np.cos(ory*3.1415/180), 0.0],\n",
    "      [ 0.0,  0.0, 0.0, 1.0]])\n",
    "    \n",
    "    OR_Z = np.array([\n",
    "      [ np.cos(orz*3.1415/180),  -np.sin(orz*3.1415/180), 0.0, 0.0],\n",
    "      [ np.sin(orz*3.1415/180),  np.cos(orz*3.1415/180), 0.0, 0.0],\n",
    "      [ 0.0,  0.0, 1.0, 0.0],\n",
    "      [ 0.0,  0.0, 0.0, 1.0]])\"\"\"\n",
    "    \n",
    "    img = 20\n",
    "    bottom = np.reshape([0, 0, 0, 1.], [1, 4])\n",
    "    pose = poses[img,:3,:4]\n",
    "    print(pose)\n",
    "    pose = np.concatenate([pose[:3, :4], bottom], -2)\n",
    "    c2w = (R_X@R_Y@R_Z@c2w@pose)[:3,:]\n",
    "    \n",
    "    #rays = generate_rays_waymo(c2w, dataset, img=img, pp=princip_point[img])\n",
    "    rays = generate_rays_original(c2w, dataset, img=img)\n",
    "    \n",
    "    init = []\n",
    "    for i in range(int(poses.shape[0]/5)):\n",
    "        init.append(np.array(\n",
    "            [np.concatenate(box_dict[str(i + 1) + '_' + str(c) + '_center'][:, None], axis=0) for c in\n",
    "                cars]).reshape(-1, 6))\n",
    "    init = np.array(init).reshape(int(poses.shape[0]/5), -1, 6)\n",
    "    box = np.array([np.concatenate(box_dict[str(1) + '_' + str(c) + '_center'][:, None], axis=0) for c in\n",
    "                 cars]).reshape(-1, 6)\n",
    "    ext = np.array([np.concatenate(box_dict[str(1) + '_' + str(c) + '_ext'][..., None], axis=0) for c in\n",
    "                 cars]).reshape(-1, 3)\n",
    "    rel = np.array([np.concatenate(rel_pose[str(1) + '_' + str(c) + '_rel'], axis=0) for c in\n",
    "                 cars]).reshape(-1, 4, 4)\n",
    "    #box_mvmt = OR_X@OR_Y@OR_Z@ot\n",
    "    #box[obj] = box_mvmt@box[obj]\n",
    "    #rel[obj] = np.linalg.inv(box_mvmt)@rel[obj]\n",
    "    \n",
    "    save = [c2w, ts]\n",
    "    traj.append(save)\n",
    "    \"\"\"\n",
    "    pred_color, pred_distance, pred_acc = obbpose_model.render_image(\n",
    "                functools.partial(render_eval_pfn, state.optimizer.target),\n",
    "                rays,\n",
    "                init,\n",
    "                ext,\n",
    "                ts,\n",
    "                None,\n",
    "                alpha=10,\n",
    "                chunk=2048)\n",
    "    \n",
    "    plt.figure(2, figsize=(20,6))\n",
    "    plt.imshow(pred_color)\n",
    "    plt.show()\n",
    "    \n",
    "    img_d = visualize_depth(pred_distance)\n",
    "    plt.figure(2, figsize=(20,6))\n",
    "    plt.imshow(img_d)\n",
    "    plt.show()\n",
    "    \n",
    "    imgsave = np.clip(pred_color, 0, 1)\n",
    "    plt.imsave(save_dir+exp_name+'_rgb_ts_'+str(ts)+'.png', imgsave)\n",
    "    img_d.save(save_dir+exp_name+'_depth_ts_'+str(ts)+'.png')\"\"\"\n",
    "    \n",
    "\n",
    "sldr = lambda : widgets.FloatSlider(\n",
    "    value=0.,\n",
    "    min=-1.,\n",
    "    max=1.,\n",
    "    step=.1,\n",
    ")\n",
    "\n",
    "names = ['x', 'y', 'z', 'rx', 'ry', 'rz', 'ts']\n",
    "    \n",
    "interactive_plot = interactive(f, \n",
    "                               x=(-1.0,1.0, 0.025),\n",
    "                               y=(-1.0,1.0, 0.025), \n",
    "                               z=(-1.0,1.0, 0.025), \n",
    "                               rx=(-20.0,20.0, 1), \n",
    "                               ry=(-90.0,90.0, 2),\n",
    "                               rz=(-20.0,20.0, 1),\n",
    "                               ts=(-4, 4, 1))\n",
    "interactive_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd705399",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(traj))\n",
    "np.savez('/home/tristram/exp_results/giftest/carla_traj.npz', traj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5681c0cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Rays = collections.namedtuple('Rays',\n",
    "('origins', 'directions', 'viewdirs', 'radii', 'lossmult', 'near', 'far'))\n",
    "\n",
    "ckpt_path = '/home/tristram/nerf_results/KITTI10_ds01_combinedD/nerf10/'\n",
    "eval_folder = '/home/tristram/exp_results/KITTI10_ds01_combinedD/'\n",
    "ref_folder = '/home/tristram/data/nerf10'\n",
    "imgs = render_traj(ckpt_path, eval_folder, ref_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0b1856",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def render_traj(ckpt_path, eval_folder, ref_folder):\n",
    "    \n",
    "    config = Config()\n",
    "\n",
    "    dataset = datasets.get_dataset('test', ref_folder, config)\n",
    "\n",
    "    model, init_variables = models.construct_mipnerf(\n",
    "          random.PRNGKey(20200823), dataset.peek())\n",
    "    optimizer = flax.optim.Adam(config.lr_init).create(init_variables)\n",
    "    state = utils.TrainState(optimizer=optimizer)\n",
    "    del optimizer, init_variables\n",
    "    \n",
    "    state = checkpoints.restore_checkpoint(ckpt_path, state)\n",
    "    \n",
    "    def render_eval_fn(variables, _, rays):\n",
    "        return jax.lax.all_gather(\n",
    "            model.apply(\n",
    "                variables,\n",
    "                random.PRNGKey(0),  # Unused.\n",
    "                rays,\n",
    "                randomized=False,\n",
    "                white_bkgd=config.white_bkgd),\n",
    "            axis_name='batch')\n",
    "\n",
    "    # pmap over only the data input.\n",
    "    render_eval_pfn = jax.pmap(\n",
    "          render_eval_fn,\n",
    "          in_axes=(None, None, 0),\n",
    "          donate_argnums=2,\n",
    "          axis_name='batch',\n",
    "      )\n",
    "    \n",
    "    if 'eval_images' not in os.listdir(eval_folder):\n",
    "        os.mkdir(eval_folder+'eval_images')\n",
    "    \n",
    "    eval_img = []\n",
    "    eval_traj = np.load(eval_folder + 'eval_traj.npy')\n",
    "    i = 0\n",
    "    for elem in eval_traj:\n",
    "        rays = generate_ndc_rays(elem, dataset)\n",
    "\n",
    "        pred_color, pred_distance, pred_acc = models.render_image(\n",
    "              functools.partial(render_eval_pfn, state.optimizer.target),\n",
    "              rays,\n",
    "              None,\n",
    "              chunk=8192)\n",
    "        print(str(i)+'/'+str(eval_traj.shape[0]))\n",
    "        plt.imsave(eval_folder + 'eval_images/' + str(i) + '.png', np.clip(pred_color, 0, 1))\n",
    "        i += 1\n",
    "    return eval_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad06540",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "bottom = np.reshape([0, 0, 0, 1.], [1, 4])\n",
    "pose = poses[0,:3,:4]\n",
    "print(pose)\n",
    "pose = np.concatenate([pose[:3, :4], bottom], -2)\n",
    "\n",
    "rays = generate_rays_original(pose, dataset)\n",
    "    \n",
    "pred_color, pred_distance, pred_acc = models.render_image(\n",
    "          functools.partial(render_eval_pfn, state.optimizer.target),\n",
    "          rays,\n",
    "          None,\n",
    "          chunk=4096)\n",
    "    \n",
    "gt_depth = np.load('/home/tristram/data/waymo/seg1_5/depth_images.npz', allow_pickle=True)['arr_0']\n",
    "print(gt_depth[4].shape)    \n",
    "    \n",
    "# save colored pointcloud of predicted depth\n",
    "h_space = np.linspace(0, 320, num=320, dtype=np.int32)\n",
    "w_space = np.linspace(0, 480, num=480, dtype=np.int32)\n",
    "\n",
    "img_d = np.meshgrid(w_space, h_space)\n",
    "pts = np.zeros((320, 480, 3))\n",
    "pts[:,:,0] = img_d[0]\n",
    "pts[:,:,1] = img_d[1]\n",
    "#depth = 1 / (1 - pred_distance)\n",
    "#depth = gt_depth[0]\n",
    "depth = pred_distance\n",
    "#depth[depth==0.0] = -1000.0\n",
    "print(depth.shape)\n",
    "pts[:,:,2] = depth.reshape(320,480)\n",
    "pts = pts.reshape(-1,3)\n",
    "\n",
    "pts_color = pred_color.reshape(-1, 3) # (H, W, 3) --> (H*W, 3)\n",
    "\n",
    "test = o3d.geometry.PointCloud(o3d.utility.Vector3dVector(pts))\n",
    "#test.colors = o3d.utility.Vector3dVector(pts_color)\n",
    "\n",
    "o3d.io.write_point_cloud(\"/home/tristram/nerf_results/WAYMO1_5_dsen_3_200_lin_8x256_8x256_256s_norand_bias01_cone/gt_depth0.ply\", test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c158c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "\n",
    "space = jnp.logspace(-0.633333333, 0., 128 + 1, endpoint=False)\n",
    "print(space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56e52a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "print(pred_color.shape)\n",
    "print(batch['pixels'].shape)\n",
    "plt.imshow(batch['pixels'])\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cbd93f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(pred_color)\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04ee6e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(traj)):\n",
    "    rays_o, rays_d = get_rays(directions, traj[i])\n",
    "    near, far = 0, 1\n",
    "    rays_o, rays_d = get_ndc_rays(int(h), int(w), focal, 1.0, rays_o, rays_d)\n",
    "    \n",
    "    rays = torch.cat([rays_o, rays_d,\n",
    "                       near*torch.ones_like(rays_o[:, :1]),\n",
    "                       far*torch.ones_like(rays_o[:, :1])],1) # (h*w, 8)\n",
    "    \n",
    "    results = inference(rays.to('cuda'))\n",
    "    img_pred = np.clip(results['rgb_fine'].view(h, w, 3).cpu().numpy(), 0, 1)\n",
    "    print(i)\n",
    "    plt.imsave('/home/tristram/Pictures/nerf_img/'+str(i)+'.png', img_pred)\n",
    "    #plt.figure(2, figsize=(20,6))\n",
    "    #plt.imshow(img_pred)\n",
    "    #plt.show()\n",
    "    #cv2.imwrite('/home/tristram/Pictures/nerf_img/'+str(i)+'.png', (img_pred*255).astype(np.int32))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
