{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b7b2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "# needed for notebook to find other directories\n",
    "module_path = os.path.abspath(os.path.join('../waymo-od'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "# needed for notebook to find other directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c679c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow.compat.v1 as tf\n",
    "import math\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "tf.enable_eager_execution()\n",
    "\n",
    "from waymo_open_dataset.utils import range_image_utils\n",
    "from waymo_open_dataset.utils import transform_utils\n",
    "from waymo_open_dataset.utils import  frame_utils\n",
    "from waymo_open_dataset import dataset_pb2 as open_dataset\n",
    "from waymo_open_dataset.utils import box_utils\n",
    "\n",
    "#from waymo_open_dataset.camera.ops import py_camera_model_ops\n",
    "\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import open3d as o3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa29ac73",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILENAME = '/home/tristram/data/waymo/training-segment-10876852935525353526_1640_000_1660_000_with_camera_labels.tfrecord'\n",
    "dataset = tf.data.TFRecordDataset(FILENAME, compression_type='')\n",
    "frames = []\n",
    "for data in dataset:\n",
    "    frame = open_dataset.Frame()\n",
    "    frame.ParseFromString(bytearray(data.numpy()))\n",
    "    frames.append(frame)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c3c253",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = frames[0]\n",
    "print(frame.laser_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3449ce36",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "id1 = frame.laser_labels[0].id\n",
    "id2 = frames[4].laser_labels[0].id\n",
    "print(id1, id2)\n",
    "#print(frame.camera_labels[1].labels[1])\n",
    "#print(frames[1].camera_labels[0].labels[0])\n",
    "cx0 = frames[0].laser_labels[0].box.center_x\n",
    "cx1 = frames[4].laser_labels[0].box.center_x\n",
    "cy0 = frames[0].laser_labels[0].box.center_y\n",
    "cy1 = frames[4].laser_labels[0].box.center_y\n",
    "cz0 = frames[0].laser_labels[0].box.center_z\n",
    "cz1 = frames[4].laser_labels[0].box.center_z\n",
    "\n",
    "coors0 = np.array([cx0, cy0, cz0])\n",
    "coors1 = np.array([cx1, cy1, cz1])\n",
    "\n",
    "t0 = np.asarray(frames[0].pose.transform).reshape(4,4)[:3,3]\n",
    "t4 = np.asarray(frames[4].pose.transform).reshape(4,4)[:3,3]\n",
    "\n",
    "coors1 = coors1 + (t0 - t4)\n",
    "print(coors1)\n",
    "print(coors0)\n",
    "print(coors1 - coors0)\n",
    "print(coors1 + (coors0 - coors1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9451b200",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = []\n",
    "cams = ['_FRONT', '_SIDE']\n",
    "for i, frame in enumerate(frames):\n",
    "    if i < 5:\n",
    "        for i, elem in enumerate(frame.projected_lidar_labels):\n",
    "                for labels in elem.labels:\n",
    "                    if labels.type == 1:\n",
    "                        if np.abs(labels.metadata.speed_x * labels.metadata.speed_y) > 10.0:\n",
    "                            for cam in cams:\n",
    "                                if cam in labels.id:\n",
    "                                    if labels.id.split(cam)[0] not in ids:\n",
    "                                        ids.append(labels.id.split(cam)[0])\n",
    "                    \"\"\"elif labels.type == 2:\n",
    "                        if np.abs(labels.metadata.speed_x * labels.metadata.speed_y) > 0.1:\n",
    "                            for cam in cams:\n",
    "                                if cam in labels.id:\n",
    "                                    if labels.id.split(cam)[0] not in ids:\n",
    "                                        ids.append(labels.id.split(cam)[0])\"\"\"\n",
    "                                    \n",
    "print(np.array(ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861b536e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign each object a number to identify it by in the mask later\n",
    "\n",
    "id_dict = {}\n",
    "for i in range(len(ids)):\n",
    "    id_dict[ids[i]] = i + 1\n",
    "    \n",
    "print(id_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf0ad7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "canonical = {}\n",
    "delta = {}\n",
    "for i, frame in enumerate(frames):\n",
    "    if 0 < i < 10:\n",
    "        cr_pose = np.asarray(frame.pose.transform).reshape(4,4)[:3,3]\n",
    "        mvmt = cn_pose - cr_pose\n",
    "        for key in id_dict:\n",
    "            for elem in frame.laser_labels:\n",
    "                if elem.id == key:\n",
    "                    # add offset from vehicle movement to bbox centers\n",
    "                    coors = np.array([elem.box.center_x, elem.box.center_y, elem.box.center_z])\n",
    "                    coors += mvmt\n",
    "                    # re-order coordinates from laser to nerf coordinate system\n",
    "                    coors = np.array([-coors[1], coors[2], -coors[0]])\n",
    "                    # this delta has to be added to move to canonical space (not subtracted)\n",
    "                    delta[str(i)+'_'+str(id_dict[key])] = canonical[key] - coors\n",
    "\n",
    "    elif i == 0:\n",
    "        cn_pose = np.asarray(frame.pose.transform).reshape(4,4)[:3,3]\n",
    "        for key in id_dict:\n",
    "            for elem in frame.laser_labels:\n",
    "                if elem.id == key:\n",
    "                    # re-order coordinates from laser to nerf coordinate system\n",
    "                    canonical[key] = np.array([-elem.box.center_y, elem.box.center_z, -elem.box.center_x])\n",
    "print(canonical)\n",
    "print(delta)\n",
    "#np.save('/home/tristram/data/waymo/seg1_5_center/delta.npy', delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7785639",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aa2matrix_old(angles):\n",
    "    \"\"\"This implements going from axis-angle to a rotation matrix representation\n",
    "        Args:\n",
    "            angles: rotation around each axis [x, y, z] in radians\n",
    "        Returns:\n",
    "            R: 3x3 rotation matrix\n",
    "    \"\"\"\n",
    "    x, y, z = angles[:3]\n",
    "    skew_r = np.array([[0., -z, y],\n",
    "                        [z, 0., -x],\n",
    "                        [-y, x, 0.]])\n",
    "    angles_norm = np.linalg.norm(angles) + 1e-12\n",
    "    R = np.eye(3) + (np.sin(angles_norm) / angles_norm) * skew_r + \\\n",
    "        ((1 - np.cos(angles_norm)) / angles_norm**2) * np.matmul(skew_r, skew_r)\n",
    "    return R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c2f1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_3d = {}\n",
    "data_dir = '/home/tristram/data/waymo/seg2_5/'\n",
    "\n",
    "opengl2waymo = np.array([[0, 0, -1, 0],\n",
    "                        [-1, 0, 0, 0],\n",
    "                        [0, 1, 0, 0],\n",
    "                        [0, 0, 0, 1]])\n",
    "\n",
    "trafo2 = np.array([[-1, 0, 0, 0],\n",
    "                        [0, 0, 1, 0],\n",
    "                        [0, 1, 0, 0],\n",
    "                        [0, 0, 0, 1]])\n",
    "\n",
    "for i, frame in enumerate(frames):\n",
    "    if 0 < i < 5:\n",
    "        v2w = np.asarray(frame.pose.transform).reshape(4,4)\n",
    "\n",
    "        for key in id_dict:\n",
    "            for elem in frame.laser_labels:\n",
    "                if elem.id == key:\n",
    "                    can_pose = np.eye(4)\n",
    "                    can_pose[:3,3] = np.array([elem.box.center_x, elem.box.center_y, elem.box.center_z])\n",
    "                    axis_angle = np.array([0.0, 0.0, elem.box.heading])\n",
    "                    rot = aa2matrix_old(axis_angle)\n",
    "                    can_pose[:3, :3] = rot\n",
    "                    can_pose = np.matmul(v2w, can_pose)\n",
    "                    can_pose = np.matmul(can_pose, opengl2waymo)\n",
    "                    can_pose = np.matmul(trafo2, can_pose)\n",
    "                    car = id_dict[key]\n",
    "                    extent = np.array([elem.box.width, elem.box.height, elem.box.length])\n",
    "                    #extent = np.array([elem.box.length, elem.box.width, elem.box.height])\n",
    "                    dict_3d[str(i+1)+'_'+str(car)+'_center'] = can_pose\n",
    "                    dict_3d[str(i+1)+'_'+str(car)+'_ext'] = extent\n",
    "    elif i == 0:\n",
    "        v2w = np.asarray(frame.pose.transform).reshape(4,4)\n",
    "        for key in id_dict:\n",
    "            for elem in frame.laser_labels:\n",
    "                if elem.id == key:\n",
    "                    can_pose = np.eye(4)\n",
    "                    can_pose[:3,3] = np.array([elem.box.center_x, elem.box.center_y, elem.box.center_z])\n",
    "                    axis_angle = np.array([0.0, 0.0, elem.box.heading])\n",
    "                    rot = aa2matrix_old(axis_angle)\n",
    "                    can_pose[:3, :3] = rot\n",
    "                    can_pose = np.matmul(v2w, can_pose)\n",
    "                    can_pose = np.matmul(can_pose, opengl2waymo)\n",
    "                    can_pose = np.matmul(trafo2, can_pose)\n",
    "                    car = id_dict[key]\n",
    "                    extent = np.array([elem.box.width, elem.box.height, elem.box.length])\n",
    "                    #extent = np.array([elem.box.length, elem.box.width, elem.box.height])\n",
    "                    dict_3d[str(i+1)+'_'+str(car)+'_center'] = can_pose\n",
    "                    dict_3d[str(i+1)+'_'+str(car)+'_ext'] = extent\n",
    "                    \n",
    "np.save(data_dir+'3D_boxes.npy', dict_3d)\n",
    "print(dict_3d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738567d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def project_point(point, camera_calibration):\n",
    "      # vehicle frame to camera sensor frame.\n",
    "    extrinsic = np.array(camera_calibration.extrinsic.transform).reshape(4, 4)\n",
    "    vehicle_to_sensor = np.linalg.inv(extrinsic)\n",
    "    point1 = np.concatenate([point, [1,]])\n",
    "    point_camera_frame = tf.einsum('ij,j->i', extrinsic, tf.constant(point1, dtype=tf.float32))\n",
    "    u_d = - point_camera_frame[1] / point_camera_frame[0]\n",
    "    v_d = - point_camera_frame[2] / point_camera_frame[0]\n",
    "\n",
    "    # add distortion model here if you'd like.\n",
    "    f_u = camera_calibration.intrinsic[0];\n",
    "    f_v = camera_calibration.intrinsic[1];\n",
    "    c_u = camera_calibration.intrinsic[2];\n",
    "    c_v = camera_calibration.intrinsic[3];\n",
    "    u_d = u_d * f_u + c_u;\n",
    "    v_d = v_d * f_v + c_v;\n",
    "\n",
    "    return [u_d.numpy(), v_d.numpy()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702afb56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "points = []\n",
    "frame = frames[0]\n",
    "center = dict_3d['1_1_center'][:3, 3]\n",
    "heading = R.from_matrix(dict_3d['1_1_center'][:3, :3])\n",
    "heading = heading.as_rotvec()[-1]\n",
    "ext = dict_3d['1_1_ext']\n",
    "l, w, h = ext / 2\n",
    "points.append(center + np.array([l, w, h]))\n",
    "points.append(center + np.array([-l, w, h]))\n",
    "points.append(center + np.array([l, -w, h]))\n",
    "points.append(center + np.array([l, w, -h]))\n",
    "points.append(center + np.array([l, -w, -h]))\n",
    "points.append(center + np.array([-l, -w, h]))\n",
    "points.append(center + np.array([-l, w, -h]))\n",
    "points.append(center + np.array([-l, -w, -h]))\n",
    "points = np.array(points)\n",
    "\n",
    "#py_camera_model_ops.world_to_image()\n",
    "\n",
    "box = tf.convert_to_tensor(np.concatenate([center, ext, [heading,]]))\n",
    "box = tf.reshape(box, (1, 7))\n",
    "\n",
    "p = box_utils.get_upright_3d_box_corners(box)\n",
    "print(p)\n",
    "img_p = []\n",
    "for i in range(8):\n",
    "    img_p.append(project_point(np.array(p[0, i]), frame.context.camera_calibrations[0]))\n",
    "\n",
    "img_p = np.array(img_p)\n",
    "print(img_p)\n",
    "img = np.array(tf.image.decode_jpeg(frame.images[1].image))\n",
    "\n",
    "K0 = np.array(frames[100].context.camera_calibrations[3].intrinsic)\n",
    "K1 = np.array(frame.context.camera_calibrations[1].intrinsic)\n",
    "K2 = np.array(frame.context.camera_calibrations[2].intrinsic)\n",
    "K3 = np.array(frame.context.camera_calibrations[3].intrinsic)\n",
    "K4 = np.array(frame.context.camera_calibrations[4].intrinsic)\n",
    "print(K0[:4])\n",
    "print(K1[:4])\n",
    "print(K2[:4])\n",
    "print(K3[:4])\n",
    "print(K4[:4])\n",
    "print(frame.context.camera_calibrations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04963089",
   "metadata": {},
   "outputs": [],
   "source": [
    "poses = np.load('/home/tristram/data/waymo/seg1_5_center/poses_bounds.npy')\n",
    "poses = poses[:, :-2].reshape(-1, 3, 5)\n",
    "poses = poses[:, :, :4]\n",
    "poses = np.concatenate([poses, np.broadcast_to([0, 0, 0, 1], (poses.shape[0], 1, 4))], axis=1)\n",
    "\n",
    "arr = []\n",
    "for keys in dict_3d:\n",
    "    if 'center' in keys:\n",
    "        arr.append(dict_3d[keys])\n",
    "arr = np.array(arr)\n",
    "#print(arr)\n",
    "poses = np.concatenate([poses, arr], axis=0)\n",
    "np.save('/home/tristram/data/waymo/boxpose.npy', poses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62845516",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_dir = '/home/tristram/data/waymo/seg2_5/'\n",
    "order = [1, 2, 4, 3, 5]\n",
    "masks = []\n",
    "for i, frame in enumerate(frames):\n",
    "    if i < 5:\n",
    "        for j, elem in enumerate(frame.projected_lidar_labels):\n",
    "            if elem.name < 4:\n",
    "                mask = np.zeros((320,480)).astype(np.int8)\n",
    "                for labels in elem.labels:\n",
    "                    if labels.type == 1:\n",
    "\n",
    "                        if np.abs(labels.metadata.speed_x * labels.metadata.speed_y) > 10.0:\n",
    "                            left_x = np.ceil((labels.box.center_x / 4.0) - 0.5 * (labels.box.length / 4.0))\n",
    "                            right_x = np.ceil((labels.box.center_x / 4.0) + 0.5 * (labels.box.length / 4.0))\n",
    "                            left_y = np.ceil((labels.box.center_y / 4.0) - 0.5 * (labels.box.width / 4.0))\n",
    "                            right_y = np.ceil((labels.box.center_y / 4.0) + 0.5 * (labels.box.width / 4.0))\n",
    "                            obj_num = id_dict[labels.id.split('_FRONT')[0]]\n",
    "                            mask[int(left_y):int(right_y), int(left_x):int(right_x)] = int(obj_num)\n",
    "                    \"\"\"elif labels.type == 2:\n",
    "\n",
    "                        if np.abs(labels.metadata.speed_x * labels.metadata.speed_y) > 0.1:\n",
    "                            left_x = np.ceil((labels.box.center_x / 4.0) - 0.5 * (labels.box.length / 4.0))\n",
    "                            right_x = np.ceil((labels.box.center_x / 4.0) + 0.5 * (labels.box.length / 4.0))\n",
    "                            left_y = np.ceil((labels.box.center_y / 4.0) - 0.5 * (labels.box.width / 4.0))\n",
    "                            right_y = np.ceil((labels.box.center_y / 4.0) + 0.5 * (labels.box.width / 4.0))\n",
    "                            obj_num = id_dict[labels.id.split('_FRONT')[0]]\n",
    "                            mask[int(left_y):int(right_y), int(left_x):int(right_x)] = obj_num\"\"\"\n",
    "            else:\n",
    "                mask = np.zeros((221,480)).astype(np.int8)\n",
    "                for labels in elem.labels:\n",
    "                    if labels.type == 1:\n",
    "\n",
    "                        if np.abs(labels.metadata.speed_x * labels.metadata.speed_y) > 10.0:\n",
    "                            left_x = np.ceil((labels.box.center_x / 4.0) - 0.5 * (labels.box.length / 4.0))\n",
    "                            right_x = np.ceil((labels.box.center_x / 4.0) + 0.5 * (labels.box.length / 4.0))\n",
    "                            left_y = np.ceil((labels.box.center_y / 4.0) - 0.5 * (labels.box.width / 4.0))\n",
    "                            right_y = np.ceil((labels.box.center_y / 4.0) + 0.5 * (labels.box.width / 4.0))\n",
    "                            obj_num = id_dict[labels.id.split('_SIDE')[0]]\n",
    "                            mask[int(left_y):int(right_y), int(left_x):int(right_x)] = int(obj_num)\n",
    "                    \"\"\"elif labels.type == 2:\n",
    "\n",
    "                        if np.abs(labels.metadata.speed_x * labels.metadata.speed_y) > 0.1:\n",
    "                            left_x = np.ceil((labels.box.center_x / 4.0) - 0.5 * (labels.box.length / 4.0))\n",
    "                            right_x = np.ceil((labels.box.center_x / 4.0) + 0.5 * (labels.box.length / 4.0))\n",
    "                            left_y = np.ceil((labels.box.center_y / 4.0) - 0.5 * (labels.box.width / 4.0))\n",
    "                            right_y = np.ceil((labels.box.center_y / 4.0) + 0.5 * (labels.box.width / 4.0))\n",
    "                            obj_num = id_dict[labels.id.split('_SIDE')[0]]\n",
    "                            mask[int(left_y):int(right_y), int(left_x):int(right_x)] = obj_num\"\"\"\n",
    "            masks.append(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef63dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(int(len(masks) / 5)):\n",
    "    temp = masks[5*i+2]\n",
    "    masks[5*i+2] = masks[5*i+3]\n",
    "    masks[5*i+3] = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a854948",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_masks = np.array(masks)\n",
    "\n",
    "print(len(all_masks))\n",
    "np.savez(data_dir+\"2D_boxes.npz\", all_masks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce850759",
   "metadata": {},
   "source": [
    "## Create Delta Image\n",
    "Assign a delta to every pixel according to its timestep and object. \n",
    "\n",
    "\n",
    "Uses delta and object masks calculated in the cells above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05dbd494",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create delta offset from canonical pose for every timestep and pixel\n",
    "\n",
    "timestep = 0\n",
    "delta_imgs = []\n",
    "for i, m in enumerate(masks):\n",
    "    if i > 0 and i % 5 == 0:\n",
    "        timestep +=1\n",
    "    dx_img = np.zeros((m.shape[0],m.shape[1], 3))\n",
    "    for keys in delta:\n",
    "        step, obj = keys.split('_')\n",
    "        step = int(step)\n",
    "        obj = int(obj)\n",
    "        if step == timestep:\n",
    "            sel = (m == obj)\n",
    "            dx_img[sel] = delta[keys]\n",
    "    delta_imgs.append(dx_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7778d06",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for d in delta_imgs:\n",
    "    dr = d.reshape(-1,3)\n",
    "    for i in range(dr.shape[0]):\n",
    "        if dr[i].any() > 0:\n",
    "            print(dr[i])\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69ed46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_imgs = np.array(delta_imgs)\n",
    "print(len(delta_imgs))\n",
    "np.savez(data_dir+'delta_masks.npz', delta_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679de973",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_masks = np.load('/home/tristram/data/waymo/seg1_5_center/'+'dynamic_masks_test.npz', allow_pickle=True)['arr_0']\n",
    "\n",
    "for m in all_masks:\n",
    "    plt.figure()\n",
    "    plt.imshow(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a781346f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "def show_camera_image(camera_image, camera_labels, layout, cmap=None):\n",
    "  \"\"\"Show a camera image and the given camera labels.\"\"\"\n",
    "\n",
    "  ax = plt.subplot(*layout)\n",
    "\n",
    "  # Draw the camera labels.\n",
    "  for camera_label in camera_labels:\n",
    "    # Ignore camera labels that do not correspond to this camera.\n",
    "    if camera_label.name != camera_image.name:\n",
    "      continue\n",
    "\n",
    "    # Iterate over the individual labels.\n",
    "    for label in camera_label.labels:\n",
    "        if label.type == 1 or label.type == 2:\n",
    "            if np.abs(label.metadata.speed_x * label.metadata.speed_y) > 10.0:\n",
    "                  # Draw the object bounding box.\n",
    "                  ax.add_patch(patches.Rectangle(\n",
    "                    xy=(label.box.center_x - 0.5 * label.box.length,\n",
    "                        label.box.center_y - 0.5 * label.box.width),\n",
    "                    width=label.box.length,\n",
    "                    height=label.box.width,\n",
    "                    linewidth=1,\n",
    "                    fill=True,\n",
    "                    edgecolor='red',\n",
    "                    facecolor='none'))\n",
    "\n",
    "  # Show the camera image.\n",
    "  plt.imshow(tf.image.decode_jpeg(camera_image.image), cmap=cmap)\n",
    "  plt.title(open_dataset.CameraName.Name.Name(camera_image.name))\n",
    "  plt.grid(False)\n",
    "  plt.axis('on')\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "for index, image in enumerate(frames[0].images):\n",
    "  show_camera_image(image, frames[0].projected_lidar_labels, [3, 3, index+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7f7a08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
